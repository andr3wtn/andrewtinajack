{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4714e489-1401-4ed8-a32e-583ade882df7",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd3760",
   "metadata": {},
   "source": [
    "### Libraries and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20319996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff7d35",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300f2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine_quality.data.features \n",
    "y = wine_quality.data.targets \n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdef338",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66a782",
   "metadata": {},
   "source": [
    "### Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eacd33",
   "metadata": {},
   "source": [
    "### YData Profiling Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b934fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4751d-0dcf-43aa-9466-08ea173e76ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dfa6a",
   "metadata": {},
   "source": [
    "### Box plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "features = df.columns[:-1]\n",
    "n_rows = (len(features) + 1) // 2\n",
    "\n",
    "plt.figure(figsize=(12, n_rows * 4))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    sns.boxplot(x='quality', y=feature, data=df)\n",
    "    plt.title(f'{feature} vs Wine Quality')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e9973",
   "metadata": {},
   "source": [
    "### Histogram of the Output Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of wine quality (target variable)\n",
    "sns.countplot(x='quality', data=df)\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161117b",
   "metadata": {},
   "source": [
    "### Histogram of the All Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = wine_quality.data.features\n",
    "y = wine_quality.data.targets\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot histogram for each input feature\n",
    "df.iloc[:, :-1].hist(bins=20, figsize=(12, 10), layout=(4, 3))  # Exclude the target column\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle('Histograms of Input Features', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beafa70",
   "metadata": {},
   "source": [
    "### Correlation Heatmap of Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True,          \n",
    "    cmap='coolwarm',     \n",
    "    fmt='.2f',           \n",
    "    linewidths=0.5,      \n",
    "    cbar_kws={'shrink': 0.8},  \n",
    "    annot_kws={\"size\": 12},     \n",
    "    square=True          \n",
    ")\n",
    "\n",
    "# Add title and labels for clarity\n",
    "plt.title('Correlation Matrix of Features', fontsize=16)\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Features', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4352b51",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c8a3b-e71e-4a35-af45-a43e3482622b",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c2b6f",
   "metadata": {},
   "source": [
    "We split data into training and testing sets, with 80% of the data in the training set, and 20% in the testing dataset, using random_state=42. We stratified using y because our target data is very imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4acb0f-95fa-4815-8ba9-bd33278afc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb7b28-bddf-4ad0-8ea0-37384e0d0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data set size:', X_train.shape[0])\n",
    "print('Testing data set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5399207-138f-4256-89f5-db1801f895f1",
   "metadata": {},
   "source": [
    "### Data Scaling\n",
    "\n",
    "We scaled the training data using standardization for models such as ANN. This was performed after the train test split to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d822db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf844f4",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf50d0",
   "metadata": {},
   "source": [
    "### Artificial Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ee6fe",
   "metadata": {},
   "source": [
    "#### ANN Training & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be69c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings to make the output cleaner\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58bd6764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix:\n",
      "[[  0   0   4   1   1   0   0]\n",
      " [  0   0  31  12   0   0   0]\n",
      " [  0   0 214 212   2   0   0]\n",
      " [  0   0 120 409  38   0   0]\n",
      " [  0   0   7 149  60   0   0]\n",
      " [  0   0   3  20  16   0   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.56      0.50      0.53       428\n",
      "           6       0.51      0.72      0.60       567\n",
      "           7       0.51      0.28      0.36       216\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.53      1300\n",
      "   macro avg       0.23      0.21      0.21      1300\n",
      "weighted avg       0.49      0.53      0.49      1300\n",
      "\n",
      "Best Mean Accuracy with raw data: 0.5315\n",
      "Best Accuracy on Test Set with raw data: 0.5254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "y_train = np.ravel(y_train)  # reshaping to avoid warning\n",
    "\n",
    "hidden_layers = [\n",
    "    (100,),            # 1 layer with 100 nodes\n",
    "    (200,),            # 1 layer with 200 nodes\n",
    "    (100, 50),         # 2 layers: 100 nodes, then 50 nodes\n",
    "    (200, 100),        # 2 layers: 200 nodes, then 100 nodes\n",
    "    (100, 50, 25)      # 3 layers: 100 -> 50 -> 25\n",
    "]\n",
    "\n",
    "# Creating a grid of hyperparameters\n",
    "param_grid_ann = {\n",
    "    'hidden_layer_sizes': hidden_layers,\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate_init': [0.005, 0.001],\n",
    "    'max_iter': [1000],\n",
    "    'alpha': [0.0005, 0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Creating ANN model\n",
    "ann_model_raw = MLPClassifier(random_state=random_state, early_stopping=True)\n",
    "\n",
    "# Performing Grid Search to find the best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search_ann_raw = GridSearchCV(estimator=ann_model_raw, param_grid=param_grid_ann, cv=4, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search_ann_raw.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_ann_raw = grid_search_ann_raw.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params_ann_raw)\n",
    "\n",
    "# Best estimator\n",
    "best_ann_model_raw = grid_search_ann_raw.best_estimator_\n",
    "y_pred_ann_raw = best_ann_model_raw.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ann_raw))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ann_raw))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ann_raw = accuracy_score(y_test, y_pred_ann_raw)\n",
    "print(f\"Best Mean Accuracy with raw data: {grid_search_ann_raw.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with raw data: {accuracy_ann_raw:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f7a7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.7s[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.2s[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.6s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.1s[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.6s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   3.2s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.2s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   5.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   4.5s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   3.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   2.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   4.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   3.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   5.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   3.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   3.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   4.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   0.9s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.1s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.2s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   3.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.0s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.001, max_iter=1000; total time=   0.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.001, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200,), learning_rate_init=0.005, max_iter=1000; total time=   2.0s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   3.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate_init=0.005, max_iter=1000; total time=   1.2s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.9s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   1.6s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.9s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   1.8s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.0s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   1.9s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   3.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate_init=0.005, max_iter=1000; total time=   2.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   3.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.3s\n",
      "[CV] END activation=logistic, alpha=0.0005, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.8s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.7s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   2.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(200, 100), learning_rate_init=0.001, max_iter=1000; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(200, 100), learning_rate_init=0.005, max_iter=1000; total time=   7.7s\n",
      "Best Hyperparameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix:\n",
      "[[  0   0   2   3   1   0   0]\n",
      " [  0   4  26  13   0   0   0]\n",
      " [  0   5 269 142  12   0   0]\n",
      " [  0   1 121 380  64   0   1]\n",
      " [  0   0   3 119  94   0   0]\n",
      " [  0   0   1  16  22   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Best Mean Accuracy with scaled data: 0.5694\n",
      "Best Accuracy on Test Set with scaled data: 0.5746\n"
     ]
    }
   ],
   "source": [
    "# Scaled data\n",
    "\n",
    "# Creating ANN model\n",
    "ann_model_scaled = MLPClassifier(random_state=random_state, early_stopping=True)\n",
    "\n",
    "# Performing Grid Search to find the best hyperparameters\n",
    "grid_search_ann_scaled = GridSearchCV(estimator=ann_model_scaled, param_grid=param_grid_ann, cv=4, n_jobs=-1, verbose=1)\n",
    "grid_search_ann_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_ann_scaled = grid_search_ann_scaled.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params_ann_scaled)\n",
    "\n",
    "# Best estimator\n",
    "best_ann_model_scaled = grid_search_ann_scaled.best_estimator_\n",
    "y_pred_ann_scaled = best_ann_model_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ann_scaled))\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_ann_scaled))\n",
    "\n",
    "accuracy_ann_scaled = accuracy_score(y_test, y_pred_ann_scaled)\n",
    "print(f\"Best Mean Accuracy with scaled data: {grid_search_ann_scaled.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with scaled data: {accuracy_ann_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Best Hyperparameters for PCA (n_components=5): {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=5):\n",
      "[[  0   0   4   2   0   0   0]\n",
      " [  0   0  28  14   1   0   0]\n",
      " [  0   0 219 201   8   0   0]\n",
      " [  0   0 131 407  29   0   0]\n",
      " [  0   0   9 168  39   0   0]\n",
      " [  0   0   4  21  14   0   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.55      0.51      0.53       428\n",
      "           6       0.50      0.72      0.59       567\n",
      "           7       0.43      0.18      0.25       216\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      1300\n",
      "   macro avg       0.21      0.20      0.20      1300\n",
      "weighted avg       0.47      0.51      0.47      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=5): 0.5320\n",
      "Best Accuracy on Test Set with PCA (n_components=5): 0.5115\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=6): {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=6):\n",
      "[[  0   0   4   1   1   0   0]\n",
      " [  0   0  21  21   1   0   0]\n",
      " [  0   0 274 135  19   0   0]\n",
      " [  0   0 182 324  61   0   0]\n",
      " [  0   0  25 119  72   0   0]\n",
      " [  0   0   6  11  22   0   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.54      0.64      0.58       428\n",
      "           6       0.53      0.57      0.55       567\n",
      "           7       0.41      0.33      0.37       216\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52      1300\n",
      "   macro avg       0.21      0.22      0.21      1300\n",
      "weighted avg       0.48      0.52      0.49      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=6): 0.5351\n",
      "Best Accuracy on Test Set with PCA (n_components=6): 0.5154\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=7): {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=7):\n",
      "[[  0   0   4   2   0   0   0]\n",
      " [  0   0  22  21   0   0   0]\n",
      " [  0   0 132 288   8   0   0]\n",
      " [  0   0  64 472  31   0   0]\n",
      " [  0   0   3 184  29   0   0]\n",
      " [  0   0   1  26  12   0   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.58      0.31      0.40       428\n",
      "           6       0.47      0.83      0.60       567\n",
      "           7       0.36      0.13      0.20       216\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      1300\n",
      "   macro avg       0.20      0.18      0.17      1300\n",
      "weighted avg       0.46      0.49      0.43      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=7): 0.5467\n",
      "Best Accuracy on Test Set with PCA (n_components=7): 0.4869\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=8): {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=8):\n",
      "[[  0   0   4   1   1   0   0]\n",
      " [  0   0  30  11   2   0   0]\n",
      " [  0   1 237 180  10   0   0]\n",
      " [  0   0 117 352  96   2   0]\n",
      " [  0   0   9 107  99   1   0]\n",
      " [  0   0   5   9  24   1   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.59      0.55      0.57       428\n",
      "           6       0.53      0.62      0.57       567\n",
      "           7       0.42      0.46      0.44       216\n",
      "           8       0.25      0.03      0.05        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.53      1300\n",
      "   macro avg       0.26      0.24      0.23      1300\n",
      "weighted avg       0.50      0.53      0.51      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=8): 0.5478\n",
      "Best Accuracy on Test Set with PCA (n_components=8): 0.5300\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=9): {'activation': 'relu', 'alpha': 0.0005, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=9):\n",
      "[[  0   0   3   1   2   0   0]\n",
      " [  1   0  27  12   3   0   0]\n",
      " [  0   0 205 197  26   0   0]\n",
      " [  0   0  95 349 123   0   0]\n",
      " [  0   0   4 101 111   0   0]\n",
      " [  0   0   1  14  24   0   0]\n",
      " [  0   0   0   0   1   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.61      0.48      0.54       428\n",
      "           6       0.52      0.62      0.56       567\n",
      "           7       0.38      0.51      0.44       216\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      1300\n",
      "   macro avg       0.22      0.23      0.22      1300\n",
      "weighted avg       0.49      0.51      0.50      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=9): 0.5532\n",
      "Best Accuracy on Test Set with PCA (n_components=9): 0.5115\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=10): {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.005, 'max_iter': 1000}\n",
      "Confusion Matrix for PCA-transformed data (n_components=10):\n",
      "[[  0   0   4   1   1   0   0]\n",
      " [  0   2  26  15   0   0   0]\n",
      " [  0   0 223 194  11   0   0]\n",
      " [  0   1 118 388  59   1   0]\n",
      " [  0   0   7 133  75   1   0]\n",
      " [  0   0   5  14  17   3   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Classification Report fr PCA-transformed data (n_components=10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.67      0.05      0.09        43\n",
      "           5       0.58      0.52      0.55       428\n",
      "           6       0.52      0.68      0.59       567\n",
      "           7       0.46      0.35      0.40       216\n",
      "           8       0.60      0.08      0.14        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.53      1300\n",
      "   macro avg       0.40      0.24      0.25      1300\n",
      "weighted avg       0.54      0.53      0.51      1300\n",
      "\n",
      "Best Mean Accuracy with PCA (n_components=10): 0.5596\n",
      "Best Accuracy on Test Set with PCA (n_components=10): 0.5315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/honghao/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for n_component in range(5, 11):\n",
    "\n",
    "    pca = PCA(n_components=n_component)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Creating ANN model\n",
    "    ann_model_pca = MLPClassifier(random_state=random_state, early_stopping=True)\n",
    "\n",
    "    # Performing Grid Search to find the best hyperparameters\n",
    "    grid_search_ann_pca = GridSearchCV(estimator=ann_model_pca, param_grid=param_grid_ann, cv=4, n_jobs=-1, verbose=1)\n",
    "    grid_search_ann_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params_ann_pca = grid_search_ann_pca.best_params_\n",
    "    print(f\"Best Hyperparameters for PCA (n_components={n_component}):\", best_params_ann_pca)\n",
    "\n",
    "    # Best estimator\n",
    "    best_ann_model_pca = grid_search_ann_pca.best_estimator_\n",
    "    y_pred_ann_pca = best_ann_model_pca.predict(X_test_pca)\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Confusion Matrix for PCA-transformed data (n_components={n_component}):\")\n",
    "    print(confusion_matrix(y_test, y_pred_ann_pca))\n",
    "    # print(f\"Classification Report fr PCA-transformed data (n_components={n_component}):\")\n",
    "    # print(classification_report(y_test, y_pred_ann_pca))\n",
    "\n",
    "    print(f\"Best Mean Accuracy with PCA (n_components={n_component}): {grid_search_ann_pca.best_score_:.4f}\")\n",
    "    print(f\"Best Accuracy on Test Set with PCA (n_components={n_component}): {accuracy_score(y_test, y_pred_ann_pca):.4f}\")\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12defd6-d6ab-4bbb-a9a4-714f3bbbe0dc",
   "metadata": {},
   "source": [
    "\n",
    "### K-Nearest Neighbors (KNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004f1863-4c89-4be0-9d68-8f1c8ec21afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba54451",
   "metadata": {},
   "source": [
    "#### kNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405959d1-a856-4492-a3b2-762c8fe7341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train.iloc[:, 0].values.ravel()) # there is some error for pandas datafram\n",
    "knn_pred = knn_classifier.predict(X_test)\n",
    "print(\"K-Nearest Neighbors Classifier\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, knn_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, knn_pred, zero_division=0))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a337d4-2612-4a7b-b3c4-8b379a98977b",
   "metadata": {},
   "source": [
    "#### Fine tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc66496-4863-4f28-b0c0-c6ac97abcb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for KNN: {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix: [[  0   0   2   4   0   0   0]\n",
      " [  0   5  23  14   1   0   0]\n",
      " [  0   3 269 138  16   2   0]\n",
      " [  0   0 108 416  41   2   0]\n",
      " [  0   0  20  89 105   2   0]\n",
      " [  0   0   3  17   6  13   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.62      0.12      0.20        43\n",
      "           5       0.63      0.63      0.63       428\n",
      "           6       0.61      0.73      0.67       567\n",
      "           7       0.62      0.49      0.55       216\n",
      "           8       0.68      0.33      0.45        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      1300\n",
      "   macro avg       0.45      0.33      0.36      1300\n",
      "weighted avg       0.62      0.62      0.61      1300\n",
      "\n",
      "Best Mean CV Accuracy with StandardScaler: 0.5905\n",
      "Best Accuracy on Test Set with StandardScaler: 0.6215\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "\n",
    "#fine tuning using Gridsearch\n",
    "param_grid_knn = { 'n_neighbors': [3, 5, 7, 9, 11, 13], 'weights': ['uniform', 'distance'], 'p': [1, 2] }\n",
    "#the 1 and 2 are different types of distance, manhattan or euclidean\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    #verbose=2\n",
    ")\n",
    "grid_search_knn.fit(X_train, y_train.iloc[:, 0].values.ravel())\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "print(\"Best Parameters for KNN:\", grid_search_knn.best_params_)\n",
    "y_best_pred_knn = best_knn.predict(X_test)\n",
    "print(\"Confusion Matrix:\",confusion_matrix(y_test, y_best_pred_knn))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_best_pred_knn, zero_division=0))\n",
    "\n",
    "print(f\"Best Mean CV Accuracy with StandardScaler: {grid_search_knn.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with StandardScaler: {accuracy_score(y_test, grid_search_knn.predict(X_test)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42149a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for SVM (C and kernel) with StandardScaler: {'n_neighbors': 11, 'p': 1, 'weights': 'distance'}\n",
      "Best Mean CV Accuracy with StandardScaler: 0.6456\n",
      "Best Accuracy on Test Set with StandardScaler: 0.6554\n"
     ]
    }
   ],
   "source": [
    "# Scaled data\n",
    "\n",
    "grid_search_knn_scaled = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    #verbose=2\n",
    ")\n",
    "grid_search_knn_scaled.fit(X_train_scaled, y_train.iloc[:, 0].values.ravel())\n",
    "best_knn_scaled = grid_search_knn_scaled.best_estimator_\n",
    "print(f\"Best Parameters for SVM (C and kernel) with StandardScaler:\", grid_search_knn_scaled.best_params_)\n",
    "print(f\"Best Mean CV Accuracy with StandardScaler: {grid_search_knn_scaled.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with StandardScaler: {accuracy_score(y_test, best_knn_scaled.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e64050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for PCA (n_components=5): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=5):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  21  15   2   0   0]\n",
      " [  0   2 265 144  17   0   0]\n",
      " [  0   1  99 422  43   2   0]\n",
      " [  0   0  21  89 104   2   0]\n",
      " [  0   0   2  19   5  13   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=5): 0.5830\n",
      "Best Accuracy on Test Set with PCA (n_components=5): 0.6223\n",
      "Best Hyperparameters for PCA (n_components=6): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=6):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  22  14   2   0   0]\n",
      " [  0   1 267 144  16   0   0]\n",
      " [  0   1 101 419  44   2   0]\n",
      " [  0   0  19  90 105   2   0]\n",
      " [  0   0   3  17   5  14   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=6): 0.5836\n",
      "Best Accuracy on Test Set with PCA (n_components=6): 0.6231\n",
      "Best Hyperparameters for PCA (n_components=7): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=7):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  22  14   2   0   0]\n",
      " [  0   1 266 145  15   1   0]\n",
      " [  0   1 105 413  46   2   0]\n",
      " [  0   0  19  87 108   2   0]\n",
      " [  0   0   2  19   5  13   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=7): 0.5863\n",
      "Best Accuracy on Test Set with PCA (n_components=7): 0.6192\n",
      "Best Hyperparameters for PCA (n_components=8): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=8):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  22  14   2   0   0]\n",
      " [  0   1 264 147  15   1   0]\n",
      " [  0   1 100 418  46   2   0]\n",
      " [  0   0  20  87 107   2   0]\n",
      " [  0   0   2  19   5  13   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=8): 0.5882\n",
      "Best Accuracy on Test Set with PCA (n_components=8): 0.6208\n",
      "Best Hyperparameters for PCA (n_components=9): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=9):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  23  13   2   0   0]\n",
      " [  0   1 269 142  15   1   0]\n",
      " [  0   1 101 418  45   2   0]\n",
      " [  0   0  17  90 107   2   0]\n",
      " [  0   0   2  18   5  14   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=9): 0.5888\n",
      "Best Accuracy on Test Set with PCA (n_components=9): 0.6254\n",
      "Best Hyperparameters for PCA (n_components=10): {'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "Confusion Matrix for PCA-transformed data (n_components=10):\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   5  24  12   2   0   0]\n",
      " [  0   1 268 143  15   1   0]\n",
      " [  0   1 100 419  45   2   0]\n",
      " [  0   0  17  90 107   2   0]\n",
      " [  0   0   2  18   5  14   0]\n",
      " [  0   0   0   1   0   0   0]]\n",
      "Best Mean Accuracy with PCA (n_components=10): 0.5896\n",
      "Best Accuracy on Test Set with PCA (n_components=10): 0.6254\n"
     ]
    }
   ],
   "source": [
    "# PCA data\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "for n_component in range(5, 11):\n",
    "    \n",
    "    pca = PCA(n_components=n_component)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Performing Grid Search to find the best hyperparameters\n",
    "    grid_search_knn_pca = GridSearchCV(\n",
    "        estimator=KNeighborsClassifier(),\n",
    "        param_grid=param_grid_knn,\n",
    "        cv=4,\n",
    "        n_jobs=-1,\n",
    "        #verbose=1\n",
    "    )\n",
    "    grid_search_knn_pca.fit(X_train_pca, y_train.iloc[:, 0].values.ravel())\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params_knn_pca = grid_search_knn_pca.best_params_\n",
    "    print(f\"Best Hyperparameters for PCA (n_components={n_component}):\", best_params_knn_pca)\n",
    "\n",
    "    # Best estimator\n",
    "    best_knn_model_pca = grid_search_knn_pca.best_estimator_\n",
    "    y_pred_knn_pca = best_knn_model_pca.predict(X_test_pca)\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Confusion Matrix for PCA-transformed data (n_components={n_component}):\")\n",
    "    print(confusion_matrix(y_test, y_pred_knn_pca))\n",
    "    #print(f\"Classification Report fr PCA-transformed data (n_components={n_component}):\")\n",
    "    #print(classification_report(y_test, y_pred_knn_pca, zero_division=1))\n",
    "\n",
    "    print(f\"Best Mean Accuracy with PCA (n_components={n_component}): {grid_search_knn_pca.best_score_:.4f}\")\n",
    "    print(f\"Best Accuracy on Test Set with PCA (n_components={n_component}): {accuracy_score(y_test, y_pred_knn_pca):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648a3d5",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce346f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.05, 0.1, 1, 5, 10, 20, 50],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train.iloc[:, 0].values.ravel())\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "print(\"Best Parameters for SVM:\", grid_search_svm.best_params_)\n",
    "y_best_pred_svm = best_svm.predict(X_test)\n",
    "print(\"Confusion Matrix:\",confusion_matrix(y_test, y_best_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_best_pred_svm, zero_division=0))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_best_pred_svm))\n",
    "print(f\"Best Mean CV Accuracy: {grid_search_svm.best_score_:.4f}\")\n",
    "\n",
    "heatmap = sns.heatmap(\n",
    "    grid_search_svm.cv_results_['mean_test_score'].reshape(len(param_grid_svm['C']), len(param_grid_svm['kernel'])),\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    xticklabels=param_grid_svm['kernel'],\n",
    "    yticklabels=param_grid_svm['C']\n",
    ")\n",
    "plt.title(\"SVM Hyperparameter Tuning Heatmap\")\n",
    "plt.xlabel(\"Kernel\")\n",
    "plt.ylabel(\"C Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_components = 7  # Set the number of components for PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "param_grid_svm = {\n",
    "        'C': [0.05, 0.1, 1, 5, 10, 20, 50],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train_pca, y_train.iloc[:, 0].values.ravel())\n",
    "\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_params = grid_search_svm.best_params_\n",
    "\n",
    "print(f\"Best Parameters for SVM (C and kernel) with PCA (n_components={n_components}):\", best_params)\n",
    "print(f\"Best Mean CV Accuracy with PCA (n_components={n_components}): {grid_search_svm.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with PCA (n_components={n_components}): {accuracy_score(y_test, best_svm.predict(X_test_pca)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ae233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train_scaled, y_train.iloc[:, 0].values.ravel())\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_params = grid_search_svm.best_params_\n",
    "\n",
    "print(f\"Best Parameters for SVM (C and kernel) with StandardScaler:\", best_params)\n",
    "print(f\"Best Mean CV Accuracy with StandardScaler: {grid_search_svm.best_score_:.4f}\")\n",
    "print(f\"Best Accuracy on Test Set with StandardScaler: {accuracy_score(y_test, best_svm.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe30b0-2f09-4fae-942d-bad77108bdc3",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39451f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_svm_classifier = SVC(kernel=grid_search.best_params_['kernel'], C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'], random_state=random_state)\n",
    "best_svm_classifier.fit(X_train_scaled, y_train.iloc[:, 0].values.ravel())\n",
    "y_pred_best_svm = best_svm_classifier.predict(X_test_scaled)\n",
    "print(\"Best SVM Classifier\")\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best_svm, zero_division=0))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred_best_svm))\n",
    "print(\"f1 Score:\", f1_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Recall Score:\", recall_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_svm))\n",
    "\n",
    "best_svm_classifier.fit(X_train, y_train.iloc[:, 0].values.ravel())\n",
    "y_pred_best_svm = best_svm_classifier.predict(X_test)\n",
    "print(\"Best SVM Classifier\")\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best_svm, zero_division=0))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred_best_svm))\n",
    "print(\"f1 Score:\", f1_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Recall Score:\", recall_score(y_test, y_pred_best_svm, average='weighted', zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2c760-839a-4089-8db2-5ceaac8638b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=13, weights='distance', p=1)\n",
    "knn_classifier.fit(X_train, y_train.iloc[:, 0].values.ravel())\n",
    "y_pred_knn_raw = knn_classifier.predict(X_test)\n",
    "\n",
    "print(\"raw KNN\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_knn_raw))\n",
    "print(\"f1 Score:\", f1_score(y_test, y_pred_knn_raw, average='weighted', zero_division=0))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_knn_raw, average='weighted', zero_division=0))\n",
    "print(\"Recall Score:\", recall_score(y_test, y_pred_knn_raw, average='weighted', zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn_raw))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn_raw, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26210fe2-360c-472c-9426-f85a1f7c8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standardized\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_knn = scaler.fit_transform(X_train)\n",
    "X_test_scaled_knn = scaler.transform(X_test)\n",
    "\n",
    "knn_classifier_scaled = KNeighborsClassifier(n_neighbors=13, weights='distance', p=1)\n",
    "knn_classifier_scaled.fit(X_train_scaled_knn, y_train.iloc[:, 0].values.ravel())\n",
    "y_pred_knn_scaled = knn_classifier_scaled.predict(X_test_scaled_knn)\n",
    "\n",
    "print(\"scaled KNN\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_knn_scaled))\n",
    "print(\"f1 Score:\", f1_score(y_test, y_pred_knn_scaled, average='weighted', zero_division=0))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_knn_scaled, average='weighted', zero_division=0))\n",
    "print(\"Recall Score:\", recall_score(y_test, y_pred_knn_scaled, average='weighted', zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn_scaled))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn_scaled, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f69f2-6547-4f5e-acc1-5a78d408e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from Table 5 and Table 6\n",
    "models = ['ANN', 'KNN', 'SVM']\n",
    "metrics = ['Accuracy', 'F1', 'Precision', 'Recall']\n",
    "\n",
    "# Raw input scores\n",
    "raw_scores = {\n",
    "    'Accuracy': [0.5108, 0.6215, 0.6169],\n",
    "    'F1': [0.54, 0.6095, 0.5812],\n",
    "    'Precision': [0.53, 0.62, 0.73],\n",
    "    'Recall': [0.57, 0.6215, 0.6169]\n",
    "}\n",
    "\n",
    "# Standardized input scores\n",
    "standardized_scores = {\n",
    "    'Accuracy': [0.6208, 0.6623, 0.6538],\n",
    "    'F1': [0.46, 0.6508, 0.6450],\n",
    "    'Precision': [0.49, 0.658, 0.6481],\n",
    "    'Recall': [0.51, 0.6623, 0.6538]\n",
    "}\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Plotting each metric separately\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(x - width/2, raw_scores[metric], width, label='Raw')\n",
    "    plt.bar(x + width/2, standardized_scores[metric], width, label='Standardized')\n",
    "    plt.xticks(x, models)\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{metric} Comparison: Raw vs Standardized Input')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251a9fc-5022-47c2-ad76-61d429ffe012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes = sorted(y_train.iloc[:, 0].unique())\n",
    "n_classes = len(classes)\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'KNN': OneVsRestClassifier(KNeighborsClassifier(n_neighbors=13, weights='distance', p=1)),\n",
    "    'SVM': OneVsRestClassifier(SVC(C=50, kernel='rbf', gamma=1, probability=True)),\n",
    "    'ANN': OneVsRestClassifier(MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42))\n",
    "}\n",
    "\n",
    "colors = cycle(['darkorange', 'blue', 'green'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for (name, model), color in zip(models.items(), colors):\n",
    "    model.fit(X_train_scaled, label_binarize(y_train.iloc[:, 0], classes=classes))\n",
    "    y_score = model.predict_proba(X_test_scaled)\n",
    "\n",
    "  \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    \n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'{name} (AUC = {roc_auc[\"micro\"]:.2f})', color=color)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Micro-Averaged ROC Curve for Multiclass Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093dc44-3c87-4af3-9a78-ffbe77ca383e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
